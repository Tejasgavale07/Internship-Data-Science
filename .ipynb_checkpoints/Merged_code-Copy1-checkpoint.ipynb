{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e944d7c",
   "metadata": {},
   "source": [
    "# PDF extraction with cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a90b306",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 42\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m d1 \u001b[38;5;241m=\u001b[39m \u001b[43md1\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,np\u001b[38;5;241m.\u001b[39mnan,regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     43\u001b[0m d1 \u001b[38;5;241m=\u001b[39m d1\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     44\u001b[0m d \u001b[38;5;241m=\u001b[39md1\n",
      "\u001b[1;31mNameError\u001b[0m: name 'd1' is not defined"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import re,csv\n",
    "import numpy as np\n",
    "\n",
    "#arguments that will read entire narration\n",
    "def tb():\n",
    "    ts={      \n",
    "         \"horizontal_strategy\":\"text\"\n",
    "    }\n",
    "    return ts\n",
    "\n",
    "#PDF extraction code\n",
    "file = r'C:\\Users\\harsh\\Desktop\\Internship digital docs\\Bank-Statements\\kalupur bank 1920.pdf'\n",
    "pdf = pdfplumber.open(file)\n",
    "pdf_text=[]\n",
    "pdf_text1=[]\n",
    "counter = 0\n",
    "for page in pdf.pages:\n",
    "    page = pdf.pages[counter] \n",
    "    pdfdata = page.extract_table()\n",
    "    dff = pd.DataFrame(pdfdata)\n",
    "    \n",
    "    try:\n",
    "        for i in dff.iloc[0]:\n",
    "            if 'Date' in str(i):\n",
    "                pdfdata = page.extract_table(tb())\n",
    "                dff = pd.DataFrame(pdfdata)\n",
    "                pdf_text.append(dff)         \n",
    "    except:\n",
    "        pass\n",
    "    counter = counter + 1\n",
    "pdf_text\n",
    "try:\n",
    "    d1 = pd.concat(pdf_text, axis=0)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    d1 = pd.concat(pdf_text1, axis=0)\n",
    "except:\n",
    "    pass\n",
    "d1 = d1.replace('',np.nan,regex=True)\n",
    "d1 = d1.replace(r'\\n',' ', regex=True)\n",
    "d =d1\n",
    "df1 = d.rename(columns = {0:\"Date\"})\n",
    "\n",
    "\n",
    "# Code of cleaning \n",
    "for i in df1.columns:\n",
    "    if 'date' in str(i).lower():\n",
    "        dat=str(i)\n",
    "        df1=df1.rename(columns = {dat:'Date'})\n",
    "df1 = df1.loc[:,~df1.columns.duplicated()] # remove duplicate columns\n",
    "# df1=df1.dropna(how='all',axis=1)\n",
    "df2 = pd.DataFrame()                       \n",
    "counter=0\n",
    "blank_df=pd.DataFrame()\n",
    "\n",
    "\n",
    "#narration shift with respect to date\n",
    "def rolling_group(val):\n",
    "    if pd.notnull(val): rolling_group.group +=1\n",
    "    return rolling_group.group\n",
    "rolling_group.group = 0\n",
    "def joinFunc(g,column):\n",
    "    col =g[column]\n",
    "    joiner = \"/\" if column == \"Date\" else \"\"\n",
    "    s = joiner.join([str(each) for each in col if pd.notnull(each)])\n",
    "    s = re.sub(\"(?<=&)\"+joiner,\" \",s)\n",
    "    s = re.sub(\"(?<=-)\"+joiner,\"\",s)\n",
    "    s = re.sub(joiner*2,joiner,s)\n",
    "    \n",
    "    return s\n",
    "groups = df1.groupby(df1['Date'].apply(rolling_group),as_index=False)\n",
    "groupFunct = lambda g: pd.Series([joinFunc(g,col) for col in g.columns],index=g.columns)\n",
    "x=groups.apply(groupFunct)\n",
    "x['Date'] = pd.to_datetime(x['Date'],errors='coerce',dayfirst=True).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "try:\n",
    "#delete rows which have opening balance etc.\n",
    "    x = x[~x['Particulars'].isin(['Opening Balance','Balance B/F','C/F','B/F','Total'])]\n",
    "    x = x[~x['Particulars'].str.contains('Opening|Closing|Brought|Carried',flags=re.IGNORECASE)]\n",
    "    print(\"Particulars\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "# data shift to our custom based headers\n",
    "list=['Date','Narration','Debit','Credit','Type','df','dfd']\n",
    "for col in x.columns:\n",
    "    x=x.replace('',np.nan)\n",
    "\n",
    "    x[col] = x[col].replace(np.nan,0)\n",
    "    x[col] = x[col].replace('NaN',0)\n",
    "    x[col] = x[col].astype(str)\n",
    "\n",
    "    if any(x[col].iloc[:5].str.contains(r'\\d{4}-\\d{2}-\\d{2}|d{2}-\\d{2}-\\d{4}', regex=True, na=True)):\n",
    "      \n",
    "        df2.insert(counter,list[counter],x[col])\n",
    "        counter+=1\n",
    "        \n",
    "    # To bundle up the Narration\n",
    "    elif any(x[col].str.len()>25):\n",
    "        x[col] = x[col].replace('nan','0')\n",
    "        x[col] = x[col].replace('-','0')\n",
    "        df2.insert(counter,list[counter],x[col])\n",
    "        counter+=1\n",
    "    \n",
    "    elif any(x[col].iloc[:5].str.contains(r'\\d+\\.\\d+', regex=True, na=True)):\n",
    "        x[col] = x[col].replace('nan','0')\n",
    "        x[col] = x[col].replace('-','0')\n",
    "        df2.insert(counter,list[counter],x[col])\n",
    "        counter+=1\n",
    "        \n",
    "\n",
    "    elif all(x[col].iloc[:5].str.contains(r'Cr|Dr|CR|DR|Credit|Debit|CREDIT|DEBIT',regex=True, na=True)):\n",
    "\n",
    "        df2['Amount'] = df2.Debit.str.cat(x[col])\n",
    "try:\n",
    "#replace nan to 0 value in credit and debit\n",
    "    df2 = df2.loc[~((df2['Credit'] == '0') & (df2['Debit'] == '0') & (df2['Date'] == '0'))]\n",
    "    df2 = df2.fillna({'Credit':0.00,'Debit':0.00})\n",
    "    df2=df2[(df2 == 0.0).sum(1) <= 2]\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df2['Credit']=df2['Credit'].replace('-',0.00)\n",
    "    df2['Debit']=df2['Debit'].replace('-',0.00)\n",
    "    df2=df2[(df2 == 0.0).sum(1) <= 2]\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    df2['Credit'] = df2['Credit'].str.extract(r'(\\d+.\\d+)').astype('float')\n",
    "    df2['Debit'] = df2['Debit'].str.extract(r'(\\d+.\\d+)').astype('float')\n",
    "except:\n",
    "    pass\n",
    "df2 = df2.fillna({'Credit':0,'Debit':0})\n",
    "\n",
    "\n",
    "df2=df2[['Date','Narration','Debit','Credit']]\n",
    "indexAge = df2[(df2['Date'] == '0')].index\n",
    "df2.drop(indexAge , inplace=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358bb873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebe4840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4567921",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
